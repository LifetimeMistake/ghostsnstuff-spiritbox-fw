from abc import ABC
import numpy as np
import pyaudio
import __audio_define as audef
import threading
import webrtcvad
import collections
import time

pa = pyaudio.PyAudio()
vad = webrtcvad.Vad(audef.mic_vad_mode)

circular_buffer = collections.deque(maxlen=audef.mic_circular_buffer_size)

_buffer_lock = threading.Lock()
_recording_event = threading.Event()
_result_buffer = np.array([], dtype=audef.mic_np_format)

def _mic_callback(in_data, frame_count, time_info, status_flags):
    global _result_buffer
    audio_frame = np.frombuffer(in_data, dtype=audef.mic_np_format)

    with _buffer_lock:
        circular_buffer.extend(audio_frame)

    if _recording_event.is_set():
        _result_buffer = np.append(_result_buffer, audio_frame)

def _vad():
    global _result_buffer
    num_voiced_frames = 0
    num_unvoiced_frames = 0

    while True:
        time.sleep(audef.mic_frame_duration_ms / 1000.0)

        with _buffer_lock:
            if len(circular_buffer) < audef.mic_frame_size:
                continue
        frame = np.array(circular_buffer)[-audef.mic_frame_size:]
        is_speech = vad.is_speech(frame.tobytes(), audef.mic_sample_rate)

        if is_speech:
            num_voiced_frames += 1
            num_unvoiced_frames = 0

            if num_voiced_frames >= audef.mic_req_voiced_frames and not _recording_event.is_set():
                with _buffer_lock:
                    _recording_event.set()
                    #_result_buffer = np.array(circular_buffer, dtype=audef.mic_np_format)
                    _result_buffer = np.append(np.array(circular_buffer, dtype=audef.mic_np_format), _result_buffer)
        else:
            if _recording_event.is_set():
                num_unvoiced_frames += 1
                if num_unvoiced_frames >= audef.mic_req_unvoiced_frames:
                    _recording_event.clear()
                    break
            else:
                num_unvoiced_frames += 1
                num_voiced_frames -= 1

def _awaitBuffer():
    global _result_buffer
    _result_buffer = np.array([], dtype=audef.mic_np_format)
    _record_stream = pa.open(format=audef.mic_pa_format, channels=audef.mic_channels, rate=audef.mic_sample_rate, input=True, frames_per_buffer=audef.mic_frame_size, stream_callback=_mic_callback)

    _record_stream.start_stream()
    _vad()

    while _recording_event.is_set():
        time.sleep(0.1)

    _record_stream.stop_stream()
    _record_stream.close()

    return _result_buffer.astype(np.float32) / 32768.0


class microphone(ABC):
    def awaitBuffer(self):
        pass

class piMic(microphone):
    def awaitBuffer(self):
        return _awaitBuffer()
    
_awaitBuffer()